{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Planteamiento\n",
    "El sitio web de dónde se obtienen los datos cuenta con bloqueo de cloud fire por lo que se usará cloudscraper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cloudscraper\n",
    "\n",
    "scraper = cloudscraper.create_scraper()\n",
    "url = 'https://es.cointelegraph.com'\n",
    "page = scraper.get(url+'/tags/bitcoin')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para tener un mayor control con los datos que se obtienen, únicamente se tomarán en cuenta los artículos que pertenezcan a la categoría noticias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "soup_page = BeautifulSoup(page.text)\n",
    "_links = soup_page.find_all('a',{'class':['post-card-inline__title-link']})\n",
    "_links = [url+x['href'] for x in _links]\n",
    "categorias = soup_page.find_all('span', {'class':['post-card-inline__badge',' post-card-inline__badge_default']})\n",
    "categorias = [x.getText() for x in categorias]\n",
    "_fechas = soup_page.find_all('time', {'class':['post-card-inline__date']})\n",
    "_fechas = [x['datetime'] for x in _fechas]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Una vez se tienen todos los enlaces, se procede a tomar directamente el contenido de cada página"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extractor(url):\n",
    "    page = scraper.get(url)\n",
    "    sp = BeautifulSoup(page.text)\n",
    "    p = sp.find_all('p')\n",
    "    text = ''\n",
    "    for r in p:\n",
    "        text += r.getText()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "enlaces, contenido, fechas = [], [], []\n",
    "for i in range(len(categorias)):\n",
    "    if 'Noticias' in categorias[i]:\n",
    "        time.sleep(3)\n",
    "        try:\n",
    "            enlaces.append(_links[i])\n",
    "            contenido.append(extractor(_links[i]))\n",
    "            fechas.append(_fechas[i])\n",
    "        except Exception as e:\n",
    "            if '404' in str(e):\n",
    "                time.sleep(3)\n",
    "                enlaces.append(_links[i])\n",
    "                contenido.append(extractor(_links[i]))\n",
    "                fechas.append(_fechas[i])\n",
    "            else:\n",
    "                print('{} \\nEn enlace: {}'.format( str(e), _links[i] ) )\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finalmente, se guardan los datos obtenidos en un archivo csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "data = pd.DataFrame({\n",
    "    'Enlace': enlaces,\n",
    "    'Texto': contenido,\n",
    "    'Fecha': fechas\n",
    "})\n",
    "data.to_csv('datos.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Con lo anterior, se obtendrán datos de mejor calidad de ahora en adelante más útiles para entrenar mejor al modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.5 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "bf2d4fae2dd7f9d0a1cb92fe5a57ae32bb8cac3d6e2203bb2bd58a3e2ed832c0"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
